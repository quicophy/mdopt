{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding a classical LDPC code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we decode a classical linear error correcting code -- Low Density Parity Check (LDPC) code.\n",
    "First, we build a Matrix Product State containing the superposition of all codewords of a code instance.\n",
    "Then, we demostrate simple decoding of a classical LDPC code using Dephasing DMRG --\n",
    "our own built-in DMRG-like optimisation algorithm to solve the main component problem --\n",
    "the problem of finding a computational basis state cotributing the most to a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import qecstruct as qec\n",
    "import matplotlib.pyplot as plt\n",
    "from mdopt.optimiser.utils import (\n",
    "    ConstraintString,\n",
    "    IDENTITY,\n",
    "    SWAP,\n",
    "    XOR_BULK,\n",
    "    XOR_LEFT,\n",
    "    XOR_RIGHT,\n",
    ")\n",
    "from examples.decoding.decoding import (\n",
    "    linear_code_constraint_sites,\n",
    "    linear_code_prepare_message,\n",
    "    linear_code_codewords,\n",
    "    linear_code_checks,\n",
    ")\n",
    "from examples.decoding.decoding import (\n",
    "    apply_bitflip_bias,\n",
    "    apply_constraints,\n",
    "    decode_linear,\n",
    ")\n",
    "from mdopt.mps.utils import (\n",
    "    create_simple_product_state,\n",
    "    create_custom_product_state,\n",
    ")\n",
    "from mdopt.utils.utils import mpo_to_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first fix a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to define the parameters of a classical LDPC code. Since our first experiment will be getting out all of the codewords, we start with a small code so that we can do a dense-form simulation to check against the MPS-MPO evolution simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BITS, NUM_CHECKS = 12, 9\n",
    "CHECK_DEGREE, BIT_DEGREE = 4, 3\n",
    "if NUM_BITS / NUM_CHECKS != CHECK_DEGREE / BIT_DEGREE:\n",
    "    raise ValueError(\"The Tanner graph of the code must be bipartite.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us construct the code object from ``qecstruct`` and prepare the initial MPS state as well as its dense-form vis-à-vis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_code = qec.random_regular_code(\n",
    "    NUM_BITS, NUM_CHECKS, BIT_DEGREE, CHECK_DEGREE, qec.Rng(SEED)\n",
    ")\n",
    "\n",
    "state = create_simple_product_state(NUM_BITS, which=\"+\")\n",
    "state_dense = state.dense(flatten=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we translate the error correcting code to the MPS-MPO language. This means we get the sites where the parity checks will be applied. We will construct MPOs using this data. These lists mention not only the sites where we will apply the XOR constraints but also other tensors, such as SWAPs (a.k.a. tensors' legs' crossings) as well as the boundary XOR constraints. In what follows we define the list of these auxiliary tensors and the corresponding sites where they should reside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_constraint_sites = linear_code_constraint_sites(example_code)\n",
    "tensors = [XOR_LEFT, XOR_BULK, SWAP, XOR_RIGHT]\n",
    "code_constraint_sites"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we are ready to check the codewords! We will do this by explicitly constructing the MPS containing equal superposition of all codewords, densifying it and finally checking all the non-zero elements. This MPS will be prepared by applying constraint MPOs to a all-plus state while renormalising it after each contraction so that the norm isn't being lost. We start with the MPS-MPO contraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = apply_constraints(\n",
    "    state,\n",
    "    code_constraint_sites,\n",
    "    tensors,\n",
    "    renormalise=True,\n",
    "    result_to_explicit=True,\n",
    "    silent=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and continue by the dense-form simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the codeword superposition state in the dense form.\n",
    "for j in tqdm(range(NUM_CHECKS)):\n",
    "    # Preparing the MPO.\n",
    "    constraint_string = ConstraintString(tensors, code_constraint_sites[j])\n",
    "    constraint_mpo = constraint_string.mpo()\n",
    "\n",
    "    # Finding the starting site of the MPS to build a correct dense-form operator.\n",
    "    START_SITE = min(constraint_string.flat())\n",
    "\n",
    "    # Preparing the dense-form operator.\n",
    "    identities_l = [IDENTITY for _ in range(START_SITE)]\n",
    "    identities_r = [\n",
    "        IDENTITY for _ in range(NUM_BITS - len(constraint_mpo) - START_SITE)\n",
    "    ]\n",
    "    full_mpo = identities_l + constraint_mpo + identities_r\n",
    "    mpo_dense = mpo_to_matrix(full_mpo, interlace=False, group=True)\n",
    "\n",
    "    # Doing the contraction in dense form.\n",
    "    state_dense = mpo_dense @ state_dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to check that the two objects represent the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tolerance under which we round tensor elements to zero.\n",
    "TOL = 1e-12\n",
    "mps_dense = state.dense(flatten=True)\n",
    "mps_dense[np.abs(mps_dense) < TOL] = 0\n",
    "\n",
    "# Retreiving codewords.\n",
    "cwords = linear_code_codewords(example_code)\n",
    "cwords_to_compare_mps = np.flatnonzero(mps_dense)\n",
    "cwords_to_compare_dense = np.flatnonzero(state_dense)\n",
    "\n",
    "print()\n",
    "print(\"Codewords from the generator matrix:\")\n",
    "print(cwords)\n",
    "print(\"Codewords from the dense-form simulation:\")\n",
    "print(cwords_to_compare_mps)\n",
    "print(\"Codewords from the MPS-form simulation:\")\n",
    "print(cwords_to_compare_dense)\n",
    "print(\"\")\n",
    "print(\n",
    "    \"All lists of codewords match:\",\n",
    "    np.logical_and(\n",
    "        np.array_equal(cwords, cwords_to_compare_mps),\n",
    "        np.array_equal(cwords_to_compare_mps, cwords_to_compare_dense),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have checked that we are able to prepare the codeword state, let's try and do the decoding. The setup is as follows: we receive a message (which might contain errors) and need to find what was the initial message. In order to do this, we first apply a bitflip bias to our MPS, which biases the state towards the received message by redistributing the amplitudes according to the Hamming distance from the message. Then, we apply the parity checks and solve the main component problem. Let's see how this works in practice. Note, that the final overlap quantity received from the algorithm can be either $0$ or $1$ (the anticipated outcome) because in the end we need a basis product state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Retreiving a perturbed codeword:\")\n",
    "print(\"\")\n",
    "\n",
    "# Defining the parameters of a classical LDPC code.\n",
    "NUM_BITS, NUM_CHECKS = 20, 15\n",
    "CHECK_DEGREE, BIT_DEGREE = 4, 3\n",
    "if NUM_BITS / NUM_CHECKS != CHECK_DEGREE / BIT_DEGREE:\n",
    "    raise ValueError(\"The Tanner graph of the code must be bipartite.\")\n",
    "\n",
    "# Defining the bias channel parameter and the error probability.\n",
    "PROB_ERROR = 0.15\n",
    "PROB_BIAS = PROB_ERROR\n",
    "\n",
    "# Maximum bond dimension and spectra cut for contractor/DMRG.\n",
    "CHI_MAX_CONTRACTOR = 1e4\n",
    "CHI_MAX_DMRG = 1e4\n",
    "CUT = 1e-12\n",
    "# Number of DMRG sweeps.\n",
    "NUM_DMRG_RUNS = 1\n",
    "\n",
    "# Constructing the code as a qecstruct object.\n",
    "example_code = qec.random_regular_code(\n",
    "    NUM_BITS, NUM_CHECKS, BIT_DEGREE, CHECK_DEGREE, qec.Rng(SEED)\n",
    ")\n",
    "\n",
    "# Getting the sites where each string of constraints should be applied.\n",
    "code_constraint_sites = linear_code_constraint_sites(example_code)\n",
    "\n",
    "# Building an initial and a perturbed codeword.\n",
    "INITIAL_CODEWORD, PERTURBED_CODEWORD = linear_code_prepare_message(\n",
    "    example_code, PROB_ERROR, error_model=qec.BinarySymmetricChannel, seed=SEED\n",
    ")\n",
    "print(\"The initial codeword is\", INITIAL_CODEWORD)\n",
    "print(\"The perturbed codeword is\", PERTURBED_CODEWORD)\n",
    "print(\"\")\n",
    "\n",
    "# Building the corresponding matrix product states.\n",
    "initial_codeword_state = create_custom_product_state(\n",
    "    INITIAL_CODEWORD, form=\"Right-canonical\"\n",
    ")\n",
    "perturbed_codeword_state = create_custom_product_state(\n",
    "    PERTURBED_CODEWORD, form=\"Right-canonical\"\n",
    ")\n",
    "\n",
    "# Applying the bitflip bias to the perturbed codeword state.\n",
    "perturbed_codeword_state = apply_bitflip_bias(\n",
    "    mps=perturbed_codeword_state,\n",
    "    sites_to_bias=\"All\",\n",
    "    prob_bias_list=PROB_BIAS,\n",
    "    renormalise=True,\n",
    ")\n",
    "\n",
    "print(\"Applying constraints:\")\n",
    "print(\"\")\n",
    "# Applying the parity constraints defined by the code.\n",
    "perturbed_codeword_state = apply_constraints(\n",
    "    perturbed_codeword_state,\n",
    "    code_constraint_sites,\n",
    "    tensors,\n",
    "    chi_max=CHI_MAX_CONTRACTOR,\n",
    "    renormalise=True,\n",
    "    result_to_explicit=False,\n",
    "    strategy=\"Naive\",\n",
    "    silent=False,\n",
    ")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Decoding:\")\n",
    "print(\"\")\n",
    "# Decoding the perturbed codeword.\n",
    "dmrg_container, success = decode_linear(\n",
    "    message=perturbed_codeword_state,\n",
    "    codeword=initial_codeword_state,\n",
    "    code=example_code,\n",
    "    num_runs=NUM_DMRG_RUNS,\n",
    "    chi_max_dmrg=CHI_MAX_DMRG,\n",
    "    cut=CUT,\n",
    "    silent=False,\n",
    ")\n",
    "print(\"\")\n",
    "print(\n",
    "    \"The overlap of the density MPO main component and the initial codeword state: \",\n",
    "    success,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now take a look at how the bond dimensions and entropies behave throughout the decoding process while applying the parity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BITS = 16\n",
    "CHI_MAX_CONTRACTOR = 1e4\n",
    "CHI_MAX_DMRG = CHI_MAX_CONTRACTOR\n",
    "PROB_ERROR = 0.15\n",
    "PROB_BIAS = PROB_ERROR\n",
    "CUT = 0\n",
    "NUM_DMRG_RUNS = 1\n",
    "NUM_EXPERIMENTS = 100\n",
    "\n",
    "SEED = 123\n",
    "seed_seq = np.random.SeedSequence(SEED)\n",
    "\n",
    "CHECK_DEGREE, BIT_DEGREE = 4, 3\n",
    "NUM_CHECKS = int(BIT_DEGREE * NUM_BITS / CHECK_DEGREE)\n",
    "if NUM_BITS / NUM_CHECKS != CHECK_DEGREE / BIT_DEGREE:\n",
    "    raise ValueError(\"The Tanner graph of the code must be bipartite.\")\n",
    "\n",
    "entropies = np.zeros((NUM_EXPERIMENTS, NUM_CHECKS, NUM_BITS - 1))\n",
    "bond_dimensions = np.zeros((NUM_EXPERIMENTS, NUM_CHECKS, NUM_BITS - 1))\n",
    "\n",
    "for l in tqdm(range(NUM_EXPERIMENTS)):\n",
    "    new_seed = seed_seq.spawn(1)[0]\n",
    "    rng = np.random.default_rng(new_seed)\n",
    "    random_integer = rng.integers(1, 10**8 + 1)\n",
    "    SEED = random_integer\n",
    "\n",
    "    code = qec.random_regular_code(\n",
    "        NUM_BITS, NUM_CHECKS, BIT_DEGREE, CHECK_DEGREE, qec.Rng(SEED)\n",
    "    )\n",
    "    code_constraint_sites = linear_code_constraint_sites(code)\n",
    "\n",
    "    INITIAL_CODEWORD, PERTURBED_CODEWORD = linear_code_prepare_message(\n",
    "        code, PROB_ERROR, error_model=qec.BinarySymmetricChannel, seed=SEED\n",
    "    )\n",
    "    tensors = [XOR_LEFT, XOR_BULK, SWAP, XOR_RIGHT]\n",
    "\n",
    "    initial_codeword_state = create_custom_product_state(\n",
    "        INITIAL_CODEWORD, form=\"Right-canonical\"\n",
    "    )\n",
    "    perturbed_codeword_state = create_custom_product_state(\n",
    "        PERTURBED_CODEWORD, form=\"Right-canonical\"\n",
    "    )\n",
    "\n",
    "    perturbed_codeword_state = apply_bitflip_bias(\n",
    "        mps=perturbed_codeword_state,\n",
    "        sites_to_bias=\"All\",\n",
    "        prob_bias_list=PROB_BIAS,\n",
    "        renormalise=True,\n",
    "    )\n",
    "    perturbed_codeword_state, entrs, bons = apply_constraints(\n",
    "        perturbed_codeword_state,\n",
    "        code_constraint_sites,\n",
    "        tensors,\n",
    "        chi_max=CHI_MAX_CONTRACTOR,\n",
    "        renormalise=True,\n",
    "        result_to_explicit=False,\n",
    "        strategy=\"Naive\",\n",
    "        silent=True,\n",
    "        return_entropies_and_bond_dims=True,\n",
    "    )\n",
    "\n",
    "    entropies[l] = np.array(entrs)\n",
    "    bond_dimensions[l] = np.array(bons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we average over all the experiments and plot the results.\n",
    "\n",
    "entropies = np.mean(entropies, axis=0)\n",
    "bond_dimensions = np.mean(bond_dimensions, axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(entropies, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Entropy\")\n",
    "plt.xlabel(\"Site number\")\n",
    "plt.ylabel(\"Time ←\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(bond_dimensions, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Bond dimension\")\n",
    "plt.ylabel(\"Time ←\")\n",
    "plt.xlabel(\"Site number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, we do see how entanglement grows during the evolution and declines towards the end!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now try to take a look at how the truncation affects the threshold for this family of codes. By definition, the threshold is the crossover error probability at which the code transitions from being unable to correct errors to being able to correct errors reliably. What we expect to see is how the logical error rate vs physical error rate curve will move up with more truncation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXPERIMENTS = 10\n",
    "CUT = 1e-12\n",
    "NUM_DMRG_RUNS = 1\n",
    "CHI_MAX_DMRG = 1e4\n",
    "\n",
    "SEED = 123\n",
    "seed_seq = np.random.SeedSequence(SEED)\n",
    "\n",
    "system_sizes = [24]\n",
    "max_bond_dims = [128, 64, 32, 16]\n",
    "error_rates = np.linspace(0.1, 0.3, 5)\n",
    "failures_statistics = {}\n",
    "\n",
    "for NUM_BITS in system_sizes:\n",
    "    for CHI_MAX_CONTRACTOR in max_bond_dims:\n",
    "        for PROB_ERROR in tqdm(error_rates):\n",
    "            failures = []\n",
    "\n",
    "            for l in range(NUM_EXPERIMENTS):\n",
    "                new_seed = seed_seq.spawn(1)[0]\n",
    "                rng = np.random.default_rng(new_seed)\n",
    "                random_integer = rng.integers(1, 10**8 + 1)\n",
    "                SEED = random_integer\n",
    "\n",
    "                CHECK_DEGREE, BIT_DEGREE = 4, 3\n",
    "                NUM_CHECKS = int(BIT_DEGREE * NUM_BITS / CHECK_DEGREE)\n",
    "                if NUM_BITS / NUM_CHECKS != CHECK_DEGREE / BIT_DEGREE:\n",
    "                    raise ValueError(\"The Tanner graph of the code must be bipartite.\")\n",
    "                PROB_BIAS = PROB_ERROR\n",
    "                CHI_MAX_DMRG = CHI_MAX_CONTRACTOR\n",
    "\n",
    "                code = qec.random_regular_code(\n",
    "                    NUM_BITS, NUM_CHECKS, BIT_DEGREE, CHECK_DEGREE, qec.Rng(SEED)\n",
    "                )\n",
    "                code_constraint_sites = linear_code_constraint_sites(code)\n",
    "\n",
    "                INITIAL_CODEWORD, PERTURBED_CODEWORD = linear_code_prepare_message(\n",
    "                    code, PROB_ERROR, error_model=qec.BinarySymmetricChannel, seed=SEED\n",
    "                )\n",
    "                tensors = [XOR_LEFT, XOR_BULK, SWAP, XOR_RIGHT]\n",
    "\n",
    "                initial_codeword_state = create_custom_product_state(\n",
    "                    INITIAL_CODEWORD, form=\"Right-canonical\"\n",
    "                )\n",
    "                perturbed_codeword_state = create_custom_product_state(\n",
    "                    PERTURBED_CODEWORD, form=\"Right-canonical\"\n",
    "                )\n",
    "\n",
    "                perturbed_codeword_state = apply_bitflip_bias(\n",
    "                    mps=perturbed_codeword_state,\n",
    "                    sites_to_bias=\"All\",\n",
    "                    prob_bias_list=PROB_BIAS,\n",
    "                    renormalise=True,\n",
    "                )\n",
    "\n",
    "                perturbed_codeword_state = apply_constraints(\n",
    "                    perturbed_codeword_state,\n",
    "                    code_constraint_sites,\n",
    "                    tensors,\n",
    "                    chi_max=CHI_MAX_CONTRACTOR,\n",
    "                    renormalise=True,\n",
    "                    result_to_explicit=False,\n",
    "                    strategy=\"Naive\",\n",
    "                    silent=True,\n",
    "                )\n",
    "\n",
    "                dmrg_container, success = decode_linear(\n",
    "                    message=perturbed_codeword_state,\n",
    "                    codeword=initial_codeword_state,\n",
    "                    code=code,\n",
    "                    num_runs=NUM_DMRG_RUNS,\n",
    "                    chi_max_dmrg=CHI_MAX_DMRG,\n",
    "                    cut=CUT,\n",
    "                    silent=True,\n",
    "                )\n",
    "                failures.append(1 - success)\n",
    "\n",
    "            failures_statistics[NUM_BITS, CHI_MAX_CONTRACTOR, PROB_ERROR] = failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_rates = {}\n",
    "error_bars = {}\n",
    "\n",
    "for system_size in system_sizes:\n",
    "    for chi_max in max_bond_dims:\n",
    "        for error_rate in error_rates:\n",
    "            failure_rates[system_size, chi_max, error_rate] = np.mean(\n",
    "                failures_statistics[system_size, chi_max, error_rate]\n",
    "            )\n",
    "            error_bars[system_size, chi_max, error_rate] = (\n",
    "                np.std(failures_statistics[system_size, chi_max, error_rate])\n",
    "                * 1.96\n",
    "                / 100\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for system_size in system_sizes:\n",
    "    for chi_max in max_bond_dims:\n",
    "        plt.errorbar(\n",
    "            error_rates,\n",
    "            [\n",
    "                failure_rates[system_size, chi_max, error_rate]\n",
    "                for error_rate in error_rates\n",
    "            ],\n",
    "            yerr=[\n",
    "                error_bars[system_size, chi_max, error_rate]\n",
    "                for error_rate in error_rates\n",
    "            ],\n",
    "            fmt=\"o--\",\n",
    "            label=f\"System size: {system_size}, max bond dim: {chi_max}\",\n",
    "        )\n",
    "plt.legend()\n",
    "plt.xlabel(\"Error rate\")\n",
    "plt.ylabel(\"Failure rate\")\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdopt-ZdbamFdU-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd00668ec6929851fcf19d7aebdf8f5927f35d0f54b527f252ebcdaf64fd8c43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
