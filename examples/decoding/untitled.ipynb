{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quimb.tensor as qtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_bsc_mps(message,nbits,prob):\n",
    "    \"\"\"\n",
    "    Returns a product state of a binary message with a binary symmetric channel\n",
    "    applied to each bit. The message is given as an int in most-significant-bit-first\n",
    "    convention. The state returned is a quimb MatrixProductState object.\n",
    "    Arguments:\n",
    "        message : int\n",
    "            The message\n",
    "        nbits : int\n",
    "            Length in bits of the message\n",
    "        prob : np.float\n",
    "            Probability of the binary symmetric channel\n",
    "    Returns:\n",
    "        mps : quimb.tensor.tensor_1d.MatrixProductState\n",
    "            Product state\n",
    "    \"\"\"\n",
    "    binx   = np.binary_repr(message,nbits)\n",
    "    arrays = np.zeros([len(binx),1,1,2])\n",
    "    noise  = np.sqrt(np.array([[1-prob,prob],[prob,1-prob]]))\n",
    "    # First two bits are logical:\n",
    "    arrays[0,0,0] = np.array([0.5,0.5])\n",
    "    arrays[1,0,0] = np.array([0.5,0.5])\n",
    "    for i,b in enumerate(binx[2:]):\n",
    "        arrays[i+2] = noise[int(b)].reshape([1,1,2])\n",
    "    mps = qtn.tensor_1d.MatrixProductState(arrays)\n",
    "    return mps\n",
    "\n",
    "def mpo_from_tensorlist(indices,tensors):\n",
    "    \"\"\"\n",
    "    Returns n-bit MPO built by stringing together given tensors.\n",
    "    Arguments:\n",
    "        indices : list of ints\n",
    "            List of tensor indices\n",
    "        tensors : list of np.array\n",
    "            List of tensors\n",
    "    Returns:\n",
    "        mpo : quimb.tensor.tensor_1d.MatrixProductOperator\n",
    "            The projector in matrix product operator form\n",
    "    \"\"\"\n",
    "    tensor_list = [tensors[i] for i in indices]\n",
    "    mpo = qtn.tensor_1d.MatrixProductOperator(tensor_list,'udlr')\n",
    "    return mpo\n",
    "\n",
    "def even_parity_mpo(bits,nbits):\n",
    "    \"\"\"\n",
    "    Returns a projector to the even-parity subspace of a subset of the bits\n",
    "    in a state. The projector returned is a quimb MatrixProductOperator object.\n",
    "    Arguments:\n",
    "        bits : list of ints\n",
    "            List of bit indices whose parity the operator will project\n",
    "        nbits : int\n",
    "            Total number of bits\n",
    "    Returns:\n",
    "        mpo : quimb.tensor.tensor_1d.MatrixProductOperator\n",
    "            The projector in matrix product operator form\n",
    "    \"\"\"\n",
    "    # Define necessary tensors; **nb** index convention is 'udlr':\n",
    "    parity        = np.zeros([2,2,2,2])\n",
    "    parity[0,0]   = np.eye(2)\n",
    "    parity[1,1]   = np.array([[0,1],[1,0]])\n",
    "    end_parity_l  = parity[:,:,0].reshape([2,2,1,2])\n",
    "    end_parity_r  = parity[:,:,0].reshape([2,2,2,1])\n",
    "    swap          = np.zeros([2,2,2,2])\n",
    "    swap[0,0]     = np.eye(2)\n",
    "    swap[1,1]     = np.eye(2)\n",
    "    iden          = np.zeros([2,2,1,1])\n",
    "    iden[:,:,0,0] = np.eye(2)\n",
    "    tensors = [iden,swap,parity,end_parity_l,end_parity_r]\n",
    "    # Build an index list, then use it to build a tensor list:\n",
    "    idrange = np.arange(nbits)\n",
    "    indices = np.zeros(nbits,int)\n",
    "    bits_sorted   = np.sort(bits)\n",
    "    indices[idrange<bits_sorted[0]]  = 0\n",
    "    indices[idrange>bits_sorted[0]]  = 1\n",
    "    indices[idrange>bits_sorted[-1]] = 0\n",
    "    indices[bits_sorted[1:-1]] = 2\n",
    "    indices[bits_sorted[0]] = 3\n",
    "    indices[bits_sorted[-1]] = 4\n",
    "    tensor_list = [tensors[i] for i in indices]\n",
    "    # Build and return the quimb MPO object:\n",
    "    mpo = qtn.tensor_1d.MatrixProductOperator(tensor_list,'udlr')\n",
    "    return mpo\n",
    "\n",
    "def logical_mpo(bits,nbits):\n",
    "    \"\"\"\n",
    "    Applies logical operator on bits.\n",
    "    \n",
    "    Arguments:\n",
    "        bits : list of ints\n",
    "            List of bit indices; first bit is logical\n",
    "        nbits : int\n",
    "            Total number of bits\n",
    "    Returns:\n",
    "        mpo : quimb.tensor.tensor_1d.MatrixProductOperator\n",
    "            The logical in matrix product operator form\n",
    "    \"\"\"\n",
    "    # Define necessary tensors; **nb** index convention is 'udlr':\n",
    "    cid           = np.zeros([2,2,1,2])\n",
    "    cid[:,0,0,:]  = np.eye(2)\n",
    "    cid[:,1,0,:]  = np.eye(2)\n",
    "    parity        = np.zeros([2,2,2,2])\n",
    "    parity[0,0]   = np.eye(2)\n",
    "    parity[1,1]   = np.array([[0,1],[1,0]])\n",
    "    end_parity_r  = parity[:,:,0].reshape([2,2,2,1])\n",
    "    swap          = np.zeros([2,2,2,2])\n",
    "    swap[0,0]     = np.eye(2)\n",
    "    swap[1,1]     = np.eye(2)\n",
    "    iden          = np.zeros([2,2,1,1])\n",
    "    iden[:,:,0,0] = np.eye(2)\n",
    "    tensors = [iden,swap,parity,cid,end_parity_r]\n",
    "    # Build an index list, then use it to build a tensor list:\n",
    "    idrange = np.arange(nbits)\n",
    "    indices = np.zeros(nbits,int)\n",
    "    bits_sorted   = np.sort(bits)\n",
    "    indices[idrange<bits_sorted[0]]  = 0\n",
    "    indices[idrange>bits_sorted[0]]  = 1\n",
    "    indices[idrange>bits_sorted[-1]] = 0\n",
    "    indices[bits_sorted[1:-1]] = 2\n",
    "    indices[bits_sorted[0]] = 3\n",
    "    indices[bits_sorted[-1]] = 4\n",
    "    tensor_list = [tensors[i] for i in indices]\n",
    "    # Build and return the quimb MPO object:\n",
    "    mpo = qtn.tensor_1d.MatrixProductOperator(tensor_list,'udlr')\n",
    "    return mpo\n",
    "\n",
    "def shor(message,bias=0.1):\n",
    "    \"\"\"\n",
    "    Returns MPS-MPO \"spacetime\" that implements Shor's code starting from\n",
    "    an error MPS with bias channel applied.\n",
    "    Arguments:\n",
    "        message : int\n",
    "            Error state in symplectic formalism; expected to be 16 bits\n",
    "        bias : float\n",
    "            Bias for the bias channel\n",
    "    Returns:\n",
    "        rdm : quimb.tensor.tensor_1d.MatrixProductOperator\n",
    "            The marginal RDM over logicals\n",
    "    \"\"\"\n",
    "    mpos = []\n",
    "    # X stabs\n",
    "    mpos.append(even_parity_mpo([2, 4, 6, 8,10,12],20))\n",
    "    mpos.append(even_parity_mpo([8,10,12,14,16,18],20))\n",
    "    # Z stabs\n",
    "    mpos.append(even_parity_mpo([ 3, 5],20))\n",
    "    mpos.append(even_parity_mpo([ 5, 7],20))\n",
    "    mpos.append(even_parity_mpo([ 9,11],20))\n",
    "    mpos.append(even_parity_mpo([11,13],20))\n",
    "    mpos.append(even_parity_mpo([15,17],20))\n",
    "    mpos.append(even_parity_mpo([17,19],20))\n",
    "    # logicals\n",
    "    mpos.append(logical_mpo([0, 2, 4, 6],20))\n",
    "    mpos.append(logical_mpo([1, 3, 9,15],20))\n",
    "    mps = initial_bsc_mps(message,20,bias)\n",
    "    mps_current = mps.copy(deep=True)\n",
    "    for mpo in mpos:\n",
    "        mps_current = mpo.apply(mps_current)\n",
    "    rdm = mps_current.ptr([0,1])\n",
    "    result = np.diag(rdm.to_dense())\n",
    "    result /= np.sum(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.000221 0.001938 0.000683 0.006005]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shor(message=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qecsim.paulitools as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_qubit_paulis = pt.ipauli(n_qubits=9, min_weight=1, max_weight=1)\n",
    "two_qubit_paulis = pt.ipauli(n_qubits=9, min_weight=2, max_weight=2)\n",
    "three_qubit_paulis = pt.ipauli(n_qubits=9, min_weight=3, max_weight=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pauli_to_mps(pauli_string: str) -> str:\n",
    "    \"\"\"\n",
    "    This function converts a Pauli string to our MPS decoder string.\n",
    "    Example: \"IXYZ\" -> \"00101101\".\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pauli_string : str\n",
    "        The Pauli string.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mps_string : str\n",
    "        The MPS string.\n",
    "    \"\"\"\n",
    "    mps_string = \"\"\n",
    "    for pauli in pauli_string:\n",
    "        if pauli == \"I\":\n",
    "            mps_string += \"00\"\n",
    "        elif pauli == \"X\":\n",
    "            mps_string += \"10\"\n",
    "        elif pauli == \"Y\":\n",
    "            mps_string += \"11\"\n",
    "        elif pauli == \"Z\":\n",
    "            mps_string += \"01\"\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid Pauli encountered -- {pauli}.\")\n",
    "\n",
    "    return mps_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_qubit_errors = [pauli_to_mps(pauli) for pauli in one_qubit_paulis]\n",
    "one_qubit_corrections = [decode_shor(error) for error in tqdm(one_qubit_errors)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
